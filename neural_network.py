# -*- coding: utf-8 -*-
"""Neural_Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/167xdpN_mYOJddkNkhjdad-5YJmQ6eRL7
"""

!pip install tensorflow

!pip install pandas

!pip install scikit-learn

# Step 2: Import libraries
import pandas as pd              # For data handling
import numpy as np               # For numerical operations
import tensorflow as tf          # For building neural network
from sklearn.model_selection import train_test_split  # For splitting data
import matplotlib.pyplot as plt   #for plotting graphs

# Step 3: Download CSV into Colab directly
csv_url = 'https://gist.githubusercontent.com/nnbphuong/def91b5553736764e8e08f6255390f37/raw/BostonHousing.csv'
df = pd.read_csv(csv_url)

# Show first few rows so students see structure
print("Dataset preview:")
print(df.head())

# Optional: rename target for clarity
df = df.rename(columns={'MEDV':'PRICE'})

# ðŸ“Š New Plot 1: Show relationship between RM (rooms) and PRICE
plt.figure(figsize=(6,4))
plt.scatter(df['RM'], df['PRICE'], alpha=0.6)
plt.title("Price vs Floor Area (Number of Rooms)")
plt.xlabel("Average Number of Rooms (RM)")
plt.ylabel("Price ($1000s)")
plt.grid(True)
plt.show()

# Step 4: Separate features (X) and label (y)
X = df.drop('PRICE', axis=1).values
y = df['PRICE'].values

# Step 5: Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Training samples: {len(X_train)}, Test samples: {len(X_test)}")

# Step 6: Normalize features for better training
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 7: Create a simple neural network model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)  # Single output: house price in $1000s
])

# Step 8: Compile the model with optimizer and loss
model.compile(
    optimizer='adam',
    loss='mean_squared_error',
    metrics=['mean_absolute_error']
)

# Step 9: Train the model
history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=100,
    verbose=1
)

# Step 10: Evaluate performance on test data
loss, mae = model.evaluate(X_test, y_test, verbose=2)
print(f"\nTest MAE: {mae*1000:.2f} USD")

# Step 11: Make predictions on test set
preds = model.predict(X_test[:20])
print("\nPredictions vs Actual prices (in $1000s):")
for pred, actual in zip(preds.flatten(), y_test[:20]):
    print(f"Predicted: {pred:.2f}, Actual: {actual:.2f}")

# Step 12: Plot training history (optional but educational)
import matplotlib.pyplot as plt
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.legend()
plt.show()

# ðŸ“Š New Plot 2: Compare predicted vs actual prices on test data
plt.figure(figsize=(6,4))
plt.plot(y_test[:20], label='Actual Price', marker='o')
plt.plot(preds[:20], label='Predicted Price', marker='x')
plt.title("Predicted vs Actual House Prices")
plt.xlabel("Sample Index")
plt.ylabel("Price ($1000s)")
plt.legend()
plt.grid(True)
plt.show()

